#!/usr/bin/env python3
"""
ç®€åŒ–ç»„ä»¶æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•æ–°å®ç°çš„ç»„ä»¶åŠŸèƒ½ï¼Œä¸ä¾èµ–å¤æ‚çš„æ•°æ®åº“æ•°æ®
"""

import logging
import pandas as pd
from datetime import datetime
from unittest.mock import Mock, patch

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def test_questionnaire_processor_comprehensive():
    """å…¨é¢æµ‹è¯•é—®å·å¤„ç†å™¨åŠŸèƒ½"""
    from app.services.questionnaire_processor import (
        QuestionnaireProcessor, QuestionnaireConfig, ScaleType
    )
    
    logger.info("=== å…¨é¢æµ‹è¯•é—®å·å¤„ç†å™¨ ===")
    
    processor = QuestionnaireProcessor()
    
    # æµ‹è¯•1ï¼š5çº§æå…‹ç‰¹é‡è¡¨
    logger.info("æµ‹è¯•1: 5çº§æå…‹ç‰¹é‡è¡¨å¤„ç†")
    test_data_5 = pd.DataFrame({
        'student_id': ['S001', 'S002', 'S003', 'S004', 'S005'] * 2,
        'question_id': ['Q1'] * 5 + ['Q2'] * 5,
        'raw_score': [5, 4, 3, 2, 1, 1, 2, 3, 4, 5],
        'dimension_code': ['å…´è¶£'] * 10,
        'dimension_name': ['å­¦ä¹ å…´è¶£'] * 10
    })
    
    configs_5 = [
        QuestionnaireConfig(
            scale_type=ScaleType.SCALE_5_LIKERT,
            question_id='Q1',
            question_name='æ‚¨å¯¹å½“å‰è¯¾ç¨‹æ„Ÿå…´è¶£å—ï¼Ÿ',
            dimension_code='å…´è¶£',
            dimension_name='å­¦ä¹ å…´è¶£'
        ),
        QuestionnaireConfig(
            scale_type=ScaleType.SCALE_5_LIKERT,
            question_id='Q2', 
            question_name='æ‚¨è®¤ä¸ºå­¦ä¹ å¾ˆæœ‰æ„ä¹‰å—ï¼Ÿ',
            dimension_code='å…´è¶£',
            dimension_name='å­¦ä¹ å…´è¶£'
        )
    ]
    
    result_5 = processor.process_questionnaire_data(test_data_5, configs_5, "TEST-5SCALE")
    
    if result_5:
        dim_stat = result_5[0]
        logger.info(f"âœ… 5çº§é‡è¡¨: ç»´åº¦å¹³å‡åˆ† {dim_stat.avg_score}, å¾—åˆ†ç‡ {dim_stat.score_rate}%")
        logger.info(f"   é€‰é¡¹åˆ†å¸ƒ: {len(dim_stat.dimension_option_distributions)} ä¸ªé€‰é¡¹")
        logger.info(f"   é¢˜ç›®æ•°é‡: {len(dim_stat.questions)} ä¸ªé¢˜ç›®")
    else:
        logger.error("âŒ 5çº§é‡è¡¨å¤„ç†å¤±è´¥")
        return False
    
    # æµ‹è¯•2ï¼š4çº§é‡è¡¨ï¼ˆåå‘ï¼‰
    logger.info("æµ‹è¯•2: 4çº§é‡è¡¨ï¼ˆåå‘ï¼‰å¤„ç†")
    test_data_4 = pd.DataFrame({
        'student_id': ['S001', 'S002', 'S003', 'S004'],
        'question_id': ['Q3'] * 4,
        'raw_score': [1, 2, 3, 4],  # åŸå§‹åˆ†æ•°
        'dimension_code': ['å‹åŠ›'] * 4,
        'dimension_name': ['å­¦ä¹ å‹åŠ›'] * 4
    })
    
    configs_4 = [
        QuestionnaireConfig(
            scale_type=ScaleType.SCALE_4_NEGATIVE,
            question_id='Q3',
            question_name='æ‚¨æ„Ÿåˆ°å­¦ä¹ å‹åŠ›å¾ˆå¤§å—ï¼Ÿ',
            dimension_code='å‹åŠ›', 
            dimension_name='å­¦ä¹ å‹åŠ›'
        )
    ]
    
    result_4 = processor.process_questionnaire_data(test_data_4, configs_4, "TEST-4SCALE")
    
    if result_4:
        dim_stat = result_4[0]
        logger.info(f"âœ… 4çº§åå‘é‡è¡¨: ç»´åº¦å¹³å‡åˆ† {dim_stat.avg_score}, å¾—åˆ†ç‡ {dim_stat.score_rate}%")
        
        # éªŒè¯åå‘è½¬æ¢ï¼š1â†’4, 2â†’3, 3â†’2, 4â†’1
        raw_scores = test_data_4['raw_score']
        transformed = processor.transform_scores(raw_scores, ScaleType.SCALE_4_NEGATIVE)
        logger.info(f"   åå‘è½¬æ¢éªŒè¯: {raw_scores.tolist()} â†’ {transformed.tolist()}")
    else:
        logger.error("âŒ 4çº§åå‘é‡è¡¨å¤„ç†å¤±è´¥")
        return False
    
    # æµ‹è¯•3ï¼š10åˆ†æ»¡æ„åº¦é‡è¡¨
    logger.info("æµ‹è¯•3: 10åˆ†æ»¡æ„åº¦é‡è¡¨å¤„ç†")
    test_data_10 = pd.DataFrame({
        'student_id': ['S001', 'S002', 'S003'],
        'question_id': ['Q4'] * 3,
        'raw_score': [10, 8, 6],
        'dimension_code': ['æ»¡æ„åº¦'] * 3,
        'dimension_name': ['æ•´ä½“æ»¡æ„åº¦'] * 3
    })
    
    configs_10 = [
        QuestionnaireConfig(
            scale_type=ScaleType.SCALE_10_SATISFACTION,
            question_id='Q4',
            question_name='æ‚¨å¯¹æ•™å­¦è´¨é‡æ»¡æ„ç¨‹åº¦ï¼Ÿ',
            dimension_code='æ»¡æ„åº¦',
            dimension_name='æ•´ä½“æ»¡æ„åº¦'
        )
    ]
    
    result_10 = processor.process_questionnaire_data(test_data_10, configs_10, "TEST-10SCALE")
    
    if result_10:
        dim_stat = result_10[0]
        logger.info(f"âœ… 10åˆ†é‡è¡¨: ç»´åº¦å¹³å‡åˆ† {dim_stat.avg_score}, å¾—åˆ†ç‡ {dim_stat.score_rate}%")
    else:
        logger.error("âŒ 10åˆ†é‡è¡¨å¤„ç†å¤±è´¥")
        return False
    
    # æµ‹è¯•4ï¼šé€‰é¡¹åˆ†å¸ƒè®¡ç®—
    logger.info("æµ‹è¯•4: é€‰é¡¹åˆ†å¸ƒè®¡ç®—ç²¾åº¦éªŒè¯")
    test_scores = pd.Series([1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5])  # 15ä¸ªæ ·æœ¬
    distributions = processor.calculate_option_distributions(test_scores, ScaleType.SCALE_5_LIKERT)
    
    expected_percentages = {
        'éå¸¸ä¸æ»¡æ„': 6.67,  # 1/15 * 100
        'ä¸æ»¡æ„': 13.33,     # 2/15 * 100
        'ä¸€èˆ¬': 20.0,       # 3/15 * 100 
        'æ»¡æ„': 26.67,      # 4/15 * 100
        'éå¸¸æ»¡æ„': 33.33   # 5/15 * 100
    }
    
    for dist in distributions:
        expected = expected_percentages.get(dist.option_label, 0)
        if abs(dist.percentage - expected) < 0.1:  # å…è®¸0.1%çš„è¯¯å·®
            logger.info(f"âœ… {dist.option_label}: {dist.percentage}% (æœŸæœ› {expected}%)")
        else:
            logger.error(f"âŒ {dist.option_label}: {dist.percentage}% (æœŸæœ› {expected}%)")
            return False
    
    logger.info("ğŸ‰ é—®å·å¤„ç†å™¨æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_aggregation_service_structure():
    """æµ‹è¯•æ±‡èšæœåŠ¡ç»“æ„å’Œæ–¹æ³•ç­¾å"""
    from app.services.simplified_aggregation_service import SimplifiedAggregationService
    
    logger.info("=== æµ‹è¯•æ±‡èšæœåŠ¡ç»“æ„ ===")
    
    # åˆ›å»ºMockæ•°æ®åº“ä¼šè¯
    mock_session = Mock()
    
    try:
        service = SimplifiedAggregationService(mock_session)
        
        # éªŒè¯åˆå§‹åŒ–
        if hasattr(service, 'questionnaire_processor'):
            logger.info("âœ… é—®å·å¤„ç†å™¨å·²åˆå§‹åŒ–")
        else:
            logger.error("âŒ é—®å·å¤„ç†å™¨æœªåˆå§‹åŒ–")
            return False
        
        if hasattr(service, 'json_serializer'):
            logger.info("âœ… JSONåºåˆ—åŒ–å™¨å·²åˆå§‹åŒ–")
        else:
            logger.error("âŒ JSONåºåˆ—åŒ–å™¨æœªåˆå§‹åŒ–") 
            return False
        
        if hasattr(service, 'calculation_engine'):
            logger.info("âœ… è®¡ç®—å¼•æ“å·²åˆå§‹åŒ–")
        else:
            logger.error("âŒ è®¡ç®—å¼•æ“æœªåˆå§‹åŒ–")
            return False
        
        # éªŒè¯ä¸»è¦æ–¹æ³•å­˜åœ¨
        required_methods = [
            'aggregate_batch_regional',
            'aggregate_batch_school', 
            'aggregate_all_batches',
            '_fetch_batch_data',
            '_analyze_batch_subjects',
            '_calculate_exam_subject_regional',
            '_calculate_questionnaire_subject_regional'
        ]
        
        for method_name in required_methods:
            if hasattr(service, method_name):
                logger.info(f"âœ… æ–¹æ³• {method_name} å­˜åœ¨")
            else:
                logger.error(f"âŒ æ–¹æ³• {method_name} ä¸å­˜åœ¨")
                return False
        
        logger.info("ğŸ‰ æ±‡èšæœåŠ¡ç»“æ„éªŒè¯é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ±‡èšæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return False


def test_repository_with_mock_session():
    """ä½¿ç”¨Mockä¼šè¯æµ‹è¯•ä»“åº“åŠŸèƒ½"""
    from app.repositories.simplified_aggregation_repository import SimplifiedAggregationRepository
    from app.database.models import AggregationLevel, CalculationStatus
    
    logger.info("=== æµ‹è¯•ä»“åº“ï¼ˆMockä¼šè¯ï¼‰===")
    
    # åˆ›å»ºMockä¼šè¯
    mock_session = Mock()
    mock_query_result = Mock()
    mock_session.query.return_value = mock_query_result
    mock_query_result.filter.return_value = mock_query_result
    mock_query_result.first.return_value = None  # æ¨¡æ‹Ÿä¸å­˜åœ¨çš„è®°å½•
    
    try:
        repository = SimplifiedAggregationRepository(mock_session)
        
        # éªŒè¯åˆå§‹åŒ–
        if hasattr(repository, 'db'):
            logger.info("âœ… æ•°æ®åº“ä¼šè¯å·²è®¾ç½®")
        else:
            logger.error("âŒ æ•°æ®åº“ä¼šè¯æœªè®¾ç½®")
            return False
        
        # éªŒè¯æ–¹æ³•å­˜åœ¨
        required_methods = [
            'save_aggregation_data',
            'get_aggregation_data',
            'update_aggregation_status',
            'get_batch_aggregation_status',
            'delete_batch_aggregations',
            'get_recent_aggregations'
        ]
        
        for method_name in required_methods:
            if hasattr(repository, method_name):
                logger.info(f"âœ… æ–¹æ³• {method_name} å­˜åœ¨")
            else:
                logger.error(f"âŒ æ–¹æ³• {method_name} ä¸å­˜åœ¨")
                return False
        
        logger.info("ğŸ‰ ä»“åº“ç»“æ„éªŒè¯é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä»“åº“æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_data_schemas():
    """æµ‹è¯•æ•°æ®æ¨¡å¼å®šä¹‰"""
    from app.schemas.simplified_aggregation_schema import (
        RegionalAggregationData, SchoolAggregationData, SubjectStatistics,
        SubjectCoreMetrics, SubjectRanking, DimensionMetrics,
        QuestionnaireOptionDistribution, QuestionnaireDimensionStats
    )
    
    logger.info("=== æµ‹è¯•æ•°æ®æ¨¡å¼ ===")
    
    try:
        # æµ‹è¯•æ ¸å¿ƒæŒ‡æ ‡æ¨¡å¼
        metrics = SubjectCoreMetrics(
            avg_score=85.5,
            difficulty=0.855,
            std_dev=12.3,
            discrimination=0.45,
            max_score=100.0,
            min_score=60.0,
            p10=70.0,
            p50=85.0,
            p90=95.0,
            student_count=150
        )
        logger.info("âœ… SubjectCoreMetrics åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ’åæ¨¡å¼
        ranking = SubjectRanking(
            school_rankings=[
                {"school_id": "S001", "school_name": "ç¬¬ä¸€ä¸­å­¦", "avg_score": 92.0, "rank": 1}
            ]
        )
        logger.info("âœ… SubjectRanking åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•é—®å·é€‰é¡¹åˆ†å¸ƒ
        option_dist = QuestionnaireOptionDistribution(
            option_label="éå¸¸æ»¡æ„",
            count=45,
            percentage=30.0
        )
        logger.info("âœ… QuestionnaireOptionDistribution åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç§‘ç›®ç»Ÿè®¡
        subject_stats = SubjectStatistics(
            subject_id="MATH_01",
            subject_name="æ•°å­¦",
            subject_type="exam",
            metrics=metrics,
            ranking=ranking
        )
        logger.info("âœ… SubjectStatistics åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åŒºåŸŸçº§æ±‡èšæ•°æ®
        regional_data = RegionalAggregationData(
            batch_code="TEST-2025",
            total_schools=10,
            total_students=1500,
            subjects={"MATH_01": subject_stats},
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat()
        )
        logger.info("âœ… RegionalAggregationData åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å­¦æ ¡çº§æ±‡èšæ•°æ®
        school_data = SchoolAggregationData(
            batch_code="TEST-2025",
            school_id="S001",
            school_name="ç¬¬ä¸€ä¸­å­¦",
            total_students=150,
            subjects={"MATH_01": subject_stats},
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat()
        )
        logger.info("âœ… SchoolAggregationData åˆ›å»ºæˆåŠŸ")
        
        logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®æ¨¡å¼éªŒè¯é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ¨¡å¼æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_utility_functions():
    """æµ‹è¯•å·¥å…·å‡½æ•°"""
    from app.schemas.simplified_aggregation_schema import (
        format_decimal, calculate_difficulty, calculate_score_rate
    )
    
    logger.info("=== æµ‹è¯•å·¥å…·å‡½æ•° ===")
    
    try:
        # æµ‹è¯•å°æ•°æ ¼å¼åŒ–
        test_cases = [
            (3.14159, 2, 3.14),
            (85.6666, 1, 85.7),
            (100.0, 2, 100.0),
            (None, 2, 0.0)
        ]
        
        for value, precision, expected in test_cases:
            result = format_decimal(value, precision)
            if result == expected:
                logger.info(f"âœ… format_decimal({value}, {precision}) = {result}")
            else:
                logger.error(f"âŒ format_decimal({value}, {precision}) = {result}, æœŸæœ› {expected}")
                return False
        
        # æµ‹è¯•éš¾åº¦ç³»æ•°è®¡ç®—
        difficulty = calculate_difficulty(85.5, 100.0)
        if difficulty == 0.85:  # 85.5/100.0 rounded to 2 decimal places
            logger.info(f"âœ… calculate_difficulty(85.5, 100.0) = {difficulty}")
        else:
            logger.error(f"âŒ calculate_difficulty(85.5, 100.0) = {difficulty}, æœŸæœ› 0.85")
            return False
        
        # æµ‹è¯•å¾—åˆ†ç‡è®¡ç®—
        score_rate = calculate_score_rate(85.5, 100.0)
        if score_rate == 85.5:  # 85.5/100.0 * 100
            logger.info(f"âœ… calculate_score_rate(85.5, 100.0) = {score_rate}%")
        else:
            logger.error(f"âŒ calculate_score_rate(85.5, 100.0) = {score_rate}%, æœŸæœ› 85.5%")
            return False
        
        logger.info("ğŸ‰ æ‰€æœ‰å·¥å…·å‡½æ•°éªŒè¯é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å·¥å…·å‡½æ•°æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹ç®€åŒ–ç»„ä»¶åŠŸèƒ½æµ‹è¯•")
    
    test_results = {
        'é—®å·å¤„ç†å™¨ï¼ˆå…¨é¢ï¼‰': test_questionnaire_processor_comprehensive(),
        'æ±‡èšæœåŠ¡ç»“æ„': test_aggregation_service_structure(),
        'ä»“åº“ï¼ˆMockä¼šè¯ï¼‰': test_repository_with_mock_session(),
        'æ•°æ®æ¨¡å¼': test_data_schemas(),
        'å·¥å…·å‡½æ•°': test_utility_functions(),
    }
    
    logger.info("=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
    success_count = 0
    for test_name, result in test_results.items():
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
        if result:
            success_count += 1
    
    logger.info(f"æ€»ä½“ç»“æœ: {success_count}/{len(test_results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if success_count == len(test_results):
        logger.info("ğŸ‰ æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼æ–°åŠŸèƒ½å®ç°å®Œæˆ")
        logger.info("")
        logger.info("ğŸ“‹ å®ç°æ€»ç»“:")
        logger.info("âœ… ä»»åŠ¡5: é—®å·æ•°æ®ç‰¹æ®Šå¤„ç†å™¨ - æ”¯æŒ3ç§é‡è¡¨ç±»å‹ï¼Œé€‰é¡¹åˆ†å¸ƒè®¡ç®—")
        logger.info("âœ… ä»»åŠ¡6: ç®€åŒ–æ±‡èšæœåŠ¡ - åŒºåŸŸçº§å’Œå­¦æ ¡çº§æ±‡èšï¼Œæ•´åˆå¤šä¸ªæ¨¡å—")  
        logger.info("âœ… ä»»åŠ¡7: æ•°æ®æŒä¹…åŒ–ä»“åº“ - ä¿å­˜ã€è¯»å–ã€çŠ¶æ€ç®¡ç†åŠŸèƒ½")
        logger.info("")
        logger.info("ğŸš€ æ ¸å¿ƒç‰¹æ€§:")
        logger.info("  â€¢ æ”¯æŒ4çº§/5çº§/10åˆ†åˆ¶é—®å·é‡è¡¨")
        logger.info("  â€¢ æ­£å‘/åå‘é‡è¡¨è‡ªåŠ¨è½¬æ¢") 
        logger.info("  â€¢ é€‰é¡¹åˆ†å¸ƒç™¾åˆ†æ¯”ç²¾ç¡®è®¡ç®—(2ä½å°æ•°)")
        logger.info("  â€¢ åŒºåŸŸçº§å­¦æ ¡æ’åå’Œå­¦æ ¡çº§åŒºåŸŸæ’å")
        logger.info("  â€¢ è€ƒè¯•ç§‘ç›®ç»´åº¦ç»Ÿè®¡å’Œé—®å·ç»´åº¦ç»Ÿè®¡")
        logger.info("  â€¢ å®Œæ•´çš„æ•°æ®ç‰ˆæœ¬ç®¡ç†å’Œå†å²è®°å½•")
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶")


if __name__ == "__main__":
    main()