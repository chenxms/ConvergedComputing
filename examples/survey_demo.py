# é—®å·æ•°æ®å¤„ç†æ¼”ç¤º
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import pandas as pd
import numpy as np
import json
import logging
from app.calculation.calculators.survey_calculator import SurveyCalculator
from app.calculation.calculators.strategy_registry import initialize_calculation_system

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_sample_survey_data():
    """åˆ›å»ºç¤ºä¾‹é—®å·æ•°æ®"""
    logger.info("åˆ›å»ºç¤ºä¾‹é—®å·æ•°æ®...")
    
    np.random.seed(42)
    n_samples = 200
    
    # åˆ›å»ºå¥½å¥‡å¿ƒå’Œè§‚å¯Ÿèƒ½åŠ›é—®å·æ•°æ®
    data = {
        # å¥½å¥‡å¿ƒç»´åº¦é¢˜ç›®
        'Q1': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.05, 0.15, 0.25, 0.35, 0.20]),  # æ­£å‘: æˆ‘å¯¹æ–°äº‹ç‰©å¾ˆæ„Ÿå…´è¶£
        'Q2': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.20, 0.35, 0.25, 0.15, 0.05]),  # åå‘: æˆ‘ä¸å–œæ¬¢æ¢ç´¢æœªçŸ¥çš„äº‹ç‰©
        'Q3': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.10, 0.15, 0.20, 0.30, 0.25]),  # æ­£å‘: æˆ‘ç»å¸¸æå‡ºé—®é¢˜
        'Q4': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.25, 0.30, 0.20, 0.15, 0.10]),  # åå‘: æˆ‘æ»¡è¶³äºç°çŠ¶ï¼Œä¸æ„¿å°è¯•æ–°æ–¹æ³•
        'Q5': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.08, 0.12, 0.25, 0.35, 0.20]),  # æ­£å‘: æˆ‘å–œæ¬¢å­¦ä¹ æ–°çŸ¥è¯†
        
        # è§‚å¯Ÿèƒ½åŠ›ç»´åº¦é¢˜ç›®
        'Q6': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.05, 0.10, 0.20, 0.40, 0.25]),  # æ­£å‘: æˆ‘èƒ½æ³¨æ„åˆ°ç»†èŠ‚
        'Q7': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.30, 0.25, 0.20, 0.15, 0.10]),  # åå‘: æˆ‘ç»å¸¸å¿½ç•¥é‡è¦ä¿¡æ¯
        'Q8': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.08, 0.15, 0.22, 0.30, 0.25]),  # æ­£å‘: æˆ‘å–„äºå‘ç°æ¨¡å¼å’Œè§„å¾‹
    }
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    
    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼æ¥æ¨¡æ‹ŸçœŸå®æ•°æ®
    for col in ['Q2', 'Q7']:
        mask = np.random.choice([True, False], n_samples, p=[0.95, 0.05])
        df[col] = df[col].where(mask, np.nan)
    
    # æ·»åŠ å“åº”æ—¶é—´æ•°æ®
    df['response_time'] = np.random.normal(300, 100, n_samples)
    df['response_time'] = np.maximum(df['response_time'], 30)
    
    # æ·»åŠ ä¸€äº›è´¨é‡é—®é¢˜æ ·æœ¬
    # ç›´çº¿å“åº”æ ·æœ¬
    for i in range(5):
        df.loc[i, 'Q1'] = 3
        df.loc[i, 'Q3'] = 3
        df.loc[i, 'Q5'] = 3
        df.loc[i, 'Q6'] = 3
        df.loc[i, 'Q8'] = 3
    
    # å®Œæˆç‡ä½çš„æ ·æœ¬
    for i in range(195, 200):
        for col in ['Q4', 'Q5', 'Q6', 'Q7']:
            df.loc[i, col] = np.nan
    
    return df


def create_survey_config():
    """åˆ›å»ºé—®å·é…ç½®"""
    return {
        'survey_id': 'curiosity_observation_survey',
        'name': 'å­¦ç”Ÿå¥½å¥‡å¿ƒä¸è§‚å¯Ÿèƒ½åŠ›è°ƒæŸ¥é—®å·',
        'dimensions': {
            'curiosity': {
                'name': 'å¥½å¥‡å¿ƒ',
                'forward_questions': ['Q1', 'Q3', 'Q5'],
                'reverse_questions': ['Q2', 'Q4'],
                'weight': 1.0,
                'description': 'è¡¡é‡å­¦ç”Ÿå¯¹æ–°äº‹ç‰©çš„å…´è¶£å’Œæ¢ç´¢æ¬²æœ›'
            },
            'observation': {
                'name': 'è§‚å¯Ÿèƒ½åŠ›',
                'forward_questions': ['Q6', 'Q8'],
                'reverse_questions': ['Q7'],
                'weight': 1.2,
                'description': 'è¡¡é‡å­¦ç”Ÿçš„è§‚å¯Ÿç»†èŠ‚å’Œå‘ç°è§„å¾‹çš„èƒ½åŠ›'
            }
        },
        'scale_config': {
            'forward': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5},  # æ­£å‘é‡è¡¨
            'reverse': {1: 5, 2: 4, 3: 3, 4: 2, 5: 1}   # åå‘é‡è¡¨
        },
        'quality_rules': {
            'response_time_min': 30,
            'response_time_max': 1800,
            'straight_line_max': 8,
            'completion_rate_min': 0.8,
            'variance_threshold': 0.1
        },
        'version': '1.0'
    }


def demonstrate_survey_processing():
    """æ¼”ç¤ºé—®å·æ•°æ®å¤„ç†åŠŸèƒ½"""
    print("=" * 80)
    print("é—®å·æ•°æ®å¤„ç†ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)
    
    # åˆå§‹åŒ–è®¡ç®—ç³»ç»Ÿ
    logger.info("åˆå§‹åŒ–è®¡ç®—ç³»ç»Ÿ...")
    initialize_calculation_system()
    
    # åˆ›å»ºè®¡ç®—å™¨
    calculator = SurveyCalculator()
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    survey_data = create_sample_survey_data()
    survey_config = create_survey_config()
    
    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"   æ ·æœ¬æ•°é‡: {len(survey_data)}")
    print(f"   é¢˜ç›®æ•°é‡: {len([col for col in survey_data.columns if col.startswith('Q')])}")
    print(f"   ç»´åº¦æ•°é‡: {len(survey_config['dimensions'])}")
    
    print(f"\nğŸ”§ ç»´åº¦é…ç½®:")
    for dim_name, dim_config in survey_config['dimensions'].items():
        forward_q = dim_config['forward_questions']
        reverse_q = dim_config['reverse_questions']
        print(f"   {dim_config['name']}: æ­£å‘é¢˜ç›®{forward_q}, åå‘é¢˜ç›®{reverse_q}, æƒé‡{dim_config['weight']}")
    
    # æ‰§è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“
    print(f"\nğŸš€ å¼€å§‹å¤„ç†é—®å·æ•°æ®...")
    results = calculator.process_survey_data(
        survey_data, 
        survey_config,
        include_quality_check=True,
        include_frequencies=True,
        include_dimensions=True
    )
    
    # å±•ç¤ºå¤„ç†ç»“æœ
    print("\n" + "=" * 80)
    print("å¤„ç†ç»“æœåˆ†æ")
    print("=" * 80)
    
    # 1. æ•°æ®è´¨é‡åˆ†æ
    print(f"\nğŸ” æ•°æ®è´¨é‡åˆ†æ:")
    quality_analysis = results['quality_analysis']
    quality_summary = quality_analysis['quality_summary']
    
    print(f"   æ€»å“åº”æ•°: {quality_summary['total_responses']}")
    print(f"   æœ‰æ•ˆå“åº”æ•°: {quality_summary['valid_responses']}")
    print(f"   æœ‰æ•ˆæ€§ç‡: {quality_summary['validity_rate']:.2%}")
    
    quality_flags = quality_analysis['quality_flags']
    print(f"   ä½å®Œæˆç‡å“åº”: {quality_flags['low_completion']['count']} ({quality_flags['low_completion']['percentage']:.1%})")
    print(f"   ç›´çº¿å“åº”: {quality_flags['straight_line']['count']} ({quality_flags['straight_line']['percentage']:.1%})")
    print(f"   æ— å˜åŒ–å“åº”: {quality_flags['no_variance']['count']} ({quality_flags['no_variance']['percentage']:.1%})")
    
    # 2. é‡è¡¨è½¬æ¢ç»“æœ
    print(f"\nğŸ”„ é‡è¡¨è½¬æ¢ç»“æœ:")
    scale_transformation = results['scale_transformation']
    transformation_summary = scale_transformation['transformation_summary']
    
    for question, info in transformation_summary.items():
        print(f"   {question} ({info['type']}é‡è¡¨): æœ‰æ•ˆè½¬æ¢{info['valid_count']}ä¸ªå“åº”")
    
    # 3. ç»´åº¦ç»Ÿè®¡åˆ†æ
    print(f"\nğŸ“ˆ ç»´åº¦ç»Ÿè®¡åˆ†æ:")
    dimension_analysis = results['dimension_analysis']
    dimension_statistics = dimension_analysis['dimension_statistics']
    
    for dim_name, stats in dimension_statistics.items():
        dim_config = survey_config['dimensions'][dim_name]
        print(f"   {dim_config['name']}ç»´åº¦:")
        print(f"     å¹³å‡åˆ†: {stats['mean']:.2f} (æƒé‡è°ƒæ•´å: {stats['weighted_mean']:.2f})")
        print(f"     æ ‡å‡†å·®: {stats['std']:.2f}")
        print(f"     æœ‰æ•ˆæ ·æœ¬: {stats['count']}")
        print(f"     åˆ†æ•°èŒƒå›´: {stats['min']:.2f} - {stats['max']:.2f}")
    
    # 4. ç»´åº¦é—´ç›¸å…³æ€§
    if 'dimension_correlations' in dimension_analysis:
        correlations = dimension_analysis['dimension_correlations']
        print(f"\nğŸ”— ç»´åº¦é—´ç›¸å…³æ€§:")
        for corr_name, corr_data in correlations.items():
            print(f"   {corr_name}: {corr_data['correlation']:.3f} ({corr_data['strength']})")
    
    # 5. é¢‘ç‡åˆ†å¸ƒåˆ†æï¼ˆå±•ç¤ºéƒ¨åˆ†é¢˜ç›®ï¼‰
    print(f"\nğŸ“Š é€‰é¡¹é¢‘ç‡åˆ†å¸ƒ (ç¤ºä¾‹é¢˜ç›®Q1):")
    frequency_analysis = results['frequency_analysis']
    q1_freq = frequency_analysis['question_frequencies']['Q1']
    
    print(f"   é€‰é¡¹åˆ†å¸ƒ:")
    for option, percentage in q1_freq['valid_percentages'].items():
        print(f"     é€‰é¡¹{option}: {q1_freq['frequencies'][option]}äºº ({percentage:.1%})")
    
    print(f"   å“åº”ç‡: {q1_freq['response_rate']:.1%}")
    print(f"   å¹³å‡åˆ†: {q1_freq['statistics']['mean']:.2f}")
    
    # 6. ç»¼åˆæŠ¥å‘Š
    print(f"\nğŸ“‹ ç»¼åˆåˆ†ææŠ¥å‘Š:")
    summary_report = results['summary_report']
    
    print("   å…³é”®å‘ç°:")
    for finding in summary_report['key_findings']:
        print(f"     â€¢ {finding}")
    
    print("   å»ºè®®:")
    for recommendation in summary_report['recommendations']:
        print(f"     â€¢ {recommendation}")
    
    # 7. æ¼”ç¤ºæ•°æ®å¯¼å‡º
    print(f"\nğŸ’¾ æ•°æ®å¯¼å‡º:")
    exported_data = calculator.export_results_to_dict(results)
    
    print(f"   å¯¼å‡ºç‰ˆæœ¬: {exported_data['survey_analysis_version']}")
    print(f"   å¤„ç†æ—¶é—´: {exported_data['processing_timestamp']}")
    print(f"   æ•°æ®å¤§å°: {len(json.dumps(exported_data, ensure_ascii=False, default=str))} å­—ç¬¦")
    
    return results


def demonstrate_individual_functions():
    """æ¼”ç¤ºå„ä¸ªç‹¬ç«‹åŠŸèƒ½"""
    print("\n" + "=" * 80)
    print("ç‹¬ç«‹åŠŸèƒ½æ¼”ç¤º")
    print("=" * 80)
    
    calculator = SurveyCalculator()
    survey_data = create_sample_survey_data()
    
    # 1. æ¼”ç¤ºé‡è¡¨è½¬æ¢
    print(f"\nğŸ”„ é‡è¡¨è½¬æ¢æ¼”ç¤º:")
    question_configs = {
        'Q1': 'forward',  # æ­£å‘é¢˜ç›®
        'Q2': 'reverse',  # åå‘é¢˜ç›®
        'Q3': 'forward'   # æ­£å‘é¢˜ç›®
    }
    
    test_data = survey_data[['Q1', 'Q2', 'Q3']].head(5)
    print("åŸå§‹æ•°æ®:")
    print(test_data.to_string(index=False))
    
    transformed_data = calculator.transform_likert_scale(test_data, question_configs, '5point')
    print("\nè½¬æ¢åæ•°æ®:")
    print(transformed_data.to_string(index=False))
    
    # 2. æ¼”ç¤ºè´¨é‡æ£€æŸ¥
    print(f"\nğŸ” è´¨é‡æ£€æŸ¥æ¼”ç¤º:")
    quality_result = calculator.analyze_response_quality(survey_data)
    
    print(f"æ€»å“åº”æ•°: {quality_result['quality_summary']['total_responses']}")
    print(f"æœ‰æ•ˆæ€§ç‡: {quality_result['quality_summary']['validity_rate']:.2%}")
    print("è´¨é‡å»ºè®®:")
    for rec in quality_result['recommendations'][:2]:  # æ˜¾ç¤ºå‰ä¸¤ä¸ªå»ºè®®
        print(f"  â€¢ {rec}")
    
    # 3. æ¼”ç¤ºé¢‘ç‡åˆ†æ
    print(f"\nğŸ“Š é¢‘ç‡åˆ†ææ¼”ç¤º (Q1é¢˜ç›®):")
    freq_result = calculator.get_frequency_distribution(survey_data, ['Q1'])
    q1_freq = freq_result['question_frequencies']['Q1']
    
    print("é€‰é¡¹é¢‘ç‡:")
    for option in sorted(q1_freq['frequencies'].keys()):
        if pd.notna(option):
            count = q1_freq['frequencies'][option]
            percentage = q1_freq['percentages'][option]
            print(f"  é€‰é¡¹{int(option)}: {count}äºº ({percentage:.1%})")


if __name__ == '__main__':
    try:
        # ä¸»è¦æ¼”ç¤º
        results = demonstrate_survey_processing()
        
        # ç‹¬ç«‹åŠŸèƒ½æ¼”ç¤º
        demonstrate_individual_functions()
        
        print("\n" + "=" * 80)
        print("æ¼”ç¤ºå®Œæˆ! ğŸ‰")
        print("é—®å·æ•°æ®å¤„ç†ç³»ç»Ÿå·²æˆåŠŸå®ç°ä»¥ä¸‹åŠŸèƒ½:")
        print("  âœ… 5çº§æå…‹ç‰¹é‡è¡¨è½¬æ¢ (æ­£å‘/åå‘)")
        print("  âœ… é€‰é¡¹é¢‘ç‡ç»Ÿè®¡å’Œåˆ†å¸ƒåˆ†æ")
        print("  âœ… å¤šç»´åº¦æ±‡æ€»è®¡ç®—å’Œç›¸å…³æ€§åˆ†æ")
        print("  âœ… æ•°æ®è´¨é‡æ£€æŸ¥å’Œå¼‚å¸¸æ£€æµ‹")
        print("  âœ… ç»¼åˆæŠ¥å‘Šç”Ÿæˆå’Œç»“æœå¯¼å‡º")
        print("=" * 80)
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()