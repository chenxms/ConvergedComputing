#!/usr/bin/env python3
"""
åˆ›å»ºæµ‹è¯•æ•°æ®è„šæœ¬
ä¸ºç³»ç»Ÿç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æ•°æ®ï¼ŒåŒ…æ‹¬å­¦ç”Ÿç­”é¢˜è®°å½•ã€ç§‘ç›®é…ç½®ã€ç»´åº¦æ˜ å°„ç­‰
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database.connection import get_session_factory
from app.database.models import StatisticalMetadata
import random
import json
from datetime import datetime, timedelta


def create_statistical_metadata():
    """åˆ›å»ºç»Ÿè®¡å…ƒæ•°æ®"""
    print("ğŸ” åˆ›å»ºç»Ÿè®¡å…ƒæ•°æ®...")
    
    try:
        SessionLocal = get_session_factory()
        
        with SessionLocal() as session:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æµ‹è¯•å…ƒæ•°æ®
            existing = session.query(StatisticalMetadata).filter(
                StatisticalMetadata.metadata_key == "test_batch_config"
            ).first()
            
            if existing:
                print("âœ… æµ‹è¯•å…ƒæ•°æ®å·²å­˜åœ¨")
                return True
            
            # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡é…ç½®
            test_config = StatisticalMetadata(
                metadata_key="test_batch_config",
                metadata_value={
                    "batch_code": "TEST_2025_001",
                    "subjects": ["æ•°å­¦", "è¯­æ–‡", "è‹±è¯­", "ç§‘å­¦"],
                    "grade_levels": ["3rd_grade", "4th_grade", "5th_grade"],
                    "total_students": 1000,
                    "schools": ["TEST_SCHOOL_001", "TEST_SCHOOL_002", "TEST_SCHOOL_003"]
                },
                description="æµ‹è¯•æ‰¹æ¬¡åŸºç¡€é…ç½®"
            )
            
            # åˆ›å»ºç§‘ç›®é…ç½®
            subject_config = StatisticalMetadata(
                metadata_key="test_subject_config",
                metadata_value={
                    "æ•°å­¦": {
                        "max_score": 100,
                        "question_count": 20,
                        "dimensions": ["æ•°å€¼è¿ç®—", "å‡ ä½•å›¾å½¢", "åº”ç”¨é¢˜"]
                    },
                    "è¯­æ–‡": {
                        "max_score": 100,
                        "question_count": 25,
                        "dimensions": ["é˜…è¯»ç†è§£", "è¯­è¨€æ–‡å­—", "å†™ä½œè¡¨è¾¾"]
                    },
                    "è‹±è¯­": {
                        "max_score": 100,
                        "question_count": 30,
                        "dimensions": ["å¬åŠ›ç†è§£", "è¯­æ³•è¯æ±‡", "é˜…è¯»èƒ½åŠ›"]
                    },
                    "ç§‘å­¦": {
                        "max_score": 100,
                        "question_count": 15,
                        "dimensions": ["è§‚å¯Ÿå®éªŒ", "ç§‘å­¦æ€ç»´", "çŸ¥è¯†ç†è§£"]
                    }
                },
                description="æµ‹è¯•ç§‘ç›®é…ç½®ä¿¡æ¯"
            )
            
            # åˆ›å»ºé—®å·é…ç½®
            survey_config = StatisticalMetadata(
                metadata_key="test_survey_config",
                metadata_value={
                    "dimensions": {
                        "å¥½å¥‡å¿ƒ": {
                            "questions": ["Q1", "Q2", "Q3"],
                            "forward_questions": ["Q1", "Q3"],
                            "reverse_questions": ["Q2"]
                        },
                        "è§‚å¯Ÿèƒ½åŠ›": {
                            "questions": ["Q4", "Q5", "Q6"],
                            "forward_questions": ["Q4", "Q6"],
                            "reverse_questions": ["Q5"]
                        }
                    },
                    "scale_type": "likert_5",
                    "total_questions": 6
                },
                description="æµ‹è¯•é—®å·é…ç½®ä¿¡æ¯"
            )
            
            session.add_all([test_config, subject_config, survey_config])
            session.commit()
            
            print("âœ… ç»Ÿè®¡å…ƒæ•°æ®åˆ›å»ºæˆåŠŸ")
            return True
            
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡å…ƒæ•°æ®åˆ›å»ºå¤±è´¥: {str(e)}")
        return False


def generate_student_scores():
    """ç”Ÿæˆå­¦ç”Ÿæˆç»©æ•°æ®"""
    print("ğŸ” ç”Ÿæˆå­¦ç”Ÿæˆç»©æµ‹è¯•æ•°æ®...")
    
    try:
        # è¿™é‡Œç”Ÿæˆå†…å­˜ä¸­çš„æµ‹è¯•æ•°æ®ï¼Œç”¨äºåç»­è®¡ç®—æµ‹è¯•
        subjects = ["æ•°å­¦", "è¯­æ–‡", "è‹±è¯­", "ç§‘å­¦"]
        grade_levels = ["3rd_grade", "4th_grade", "5th_grade"]
        schools = ["TEST_SCHOOL_001", "TEST_SCHOOL_002", "TEST_SCHOOL_003"]
        
        student_data = []
        
        for i in range(100):  # ç”Ÿæˆ100ä¸ªæµ‹è¯•å­¦ç”Ÿ
            student_id = f"STU_{i+1:04d}"
            grade_level = random.choice(grade_levels)
            school_id = random.choice(schools)
            
            student_record = {
                "student_id": student_id,
                "grade_level": grade_level,
                "school_id": school_id,
                "scores": {}
            }
            
            # ä¸ºæ¯ä¸ªç§‘ç›®ç”Ÿæˆåˆ†æ•°
            for subject in subjects:
                # æ ¹æ®å¹´çº§è°ƒæ•´åˆ†æ•°åˆ†å¸ƒ
                if grade_level == "3rd_grade":
                    base_score = random.normalvariate(75, 15)
                elif grade_level == "4th_grade":
                    base_score = random.normalvariate(80, 12)
                else:  # 5th_grade
                    base_score = random.normalvariate(85, 10)
                
                # é™åˆ¶åˆ†æ•°èŒƒå›´
                score = max(0, min(100, int(base_score)))
                student_record["scores"][subject] = score
            
            student_data.append(student_record)
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with open("test_student_data.json", "w", encoding="utf-8") as f:
            json.dump(student_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å­¦ç”Ÿæˆç»©æ•°æ®ç”ŸæˆæˆåŠŸï¼Œå…± {len(student_data)} æ¡è®°å½•")
        print("   æ•°æ®å·²ä¿å­˜åˆ°: test_student_data.json")
        return True, student_data
        
    except Exception as e:
        print(f"âŒ å­¦ç”Ÿæˆç»©æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")
        return False, []


def generate_survey_data():
    """ç”Ÿæˆé—®å·è°ƒæŸ¥æ•°æ®"""
    print("ğŸ” ç”Ÿæˆé—®å·è°ƒæŸ¥æµ‹è¯•æ•°æ®...")
    
    try:
        survey_data = []
        
        for i in range(100):
            student_id = f"STU_{i+1:04d}"
            
            # ç”Ÿæˆ6ä¸ªé—®é¢˜çš„ç­”æ¡ˆï¼ˆ1-5åˆ†ï¼‰
            responses = {}
            for q in range(1, 7):
                # æ¨¡æ‹ŸçœŸå®é—®å·å“åº”åˆ†å¸ƒ
                if random.random() < 0.1:  # 10%æç«¯å›ç­”
                    responses[f"Q{q}"] = random.choice([1, 5])
                else:  # 90%æ­£å¸¸åˆ†å¸ƒ
                    responses[f"Q{q}"] = random.choices([1, 2, 3, 4, 5], 
                                                      weights=[5, 15, 40, 30, 10])[0]
            
            survey_record = {
                "student_id": student_id,
                "responses": responses,
                "completion_time": random.randint(60, 300)  # 1-5åˆ†é’Ÿ
            }
            
            survey_data.append(survey_record)
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with open("test_survey_data.json", "w", encoding="utf-8") as f:
            json.dump(survey_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… é—®å·è°ƒæŸ¥æ•°æ®ç”ŸæˆæˆåŠŸï¼Œå…± {len(survey_data)} æ¡è®°å½•")
        print("   æ•°æ®å·²ä¿å­˜åˆ°: test_survey_data.json")
        return True, survey_data
        
    except Exception as e:
        print(f"âŒ é—®å·è°ƒæŸ¥æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")
        return False, []


def create_calculation_test_data():
    """åˆ›å»ºè®¡ç®—å¼•æ“æµ‹è¯•æ•°æ®"""
    print("ğŸ” åˆ›å»ºè®¡ç®—å¼•æ“æµ‹è¯•æ•°æ®...")
    
    try:
        # åŠ è½½å­¦ç”Ÿæ•°æ®
        with open("test_student_data.json", "r", encoding="utf-8") as f:
            student_data = json.load(f)
        
        # åŠ è½½é—®å·æ•°æ®
        with open("test_survey_data.json", "r", encoding="utf-8") as f:
            survey_data = json.load(f)
        
        # ä¸ºè®¡ç®—å¼•æ“å‡†å¤‡æ•°æ®æ ¼å¼
        calc_test_data = {
            "batch_code": "TEST_2025_001",
            "subjects": {
                "æ•°å­¦": [s["scores"]["æ•°å­¦"] for s in student_data],
                "è¯­æ–‡": [s["scores"]["è¯­æ–‡"] for s in student_data],
                "è‹±è¯­": [s["scores"]["è‹±è¯­"] for s in student_data],
                "ç§‘å­¦": [s["scores"]["ç§‘å­¦"] for s in student_data]
            },
            "survey_responses": survey_data,
            "metadata": {
                "total_students": len(student_data),
                "subjects_count": 4,
                "max_score": 100,
                "grade_levels": ["3rd_grade", "4th_grade", "5th_grade"]
            }
        }
        
        # ä¿å­˜è®¡ç®—æµ‹è¯•æ•°æ®
        with open("calculation_test_data.json", "w", encoding="utf-8") as f:
            json.dump(calc_test_data, f, ensure_ascii=False, indent=2)
        
        print("âœ… è®¡ç®—å¼•æ“æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ")
        print("   æ•°æ®å·²ä¿å­˜åˆ°: calculation_test_data.json")
        
        # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
        print("\nğŸ“Š æµ‹è¯•æ•°æ®æ¦‚è§ˆ:")
        print(f"   æ€»å­¦ç”Ÿæ•°: {calc_test_data['metadata']['total_students']}")
        print(f"   ç§‘ç›®æ•°: {calc_test_data['metadata']['subjects_count']}")
        for subject, scores in calc_test_data['subjects'].items():
            avg_score = sum(scores) / len(scores)
            print(f"   {subject}å¹³å‡åˆ†: {avg_score:.1f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®¡ç®—å¼•æ“æµ‹è¯•æ•°æ®åˆ›å»ºå¤±è´¥: {str(e)}")
        return False


def cleanup_old_test_data():
    """æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®"""
    print("ğŸ” æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®...")
    
    files_to_remove = [
        "test_student_data.json",
        "test_survey_data.json", 
        "calculation_test_data.json"
    ]
    
    for file_name in files_to_remove:
        if os.path.exists(file_name):
            os.remove(file_name)
            print(f"   æ¸…ç†: {file_name}")
    
    print("âœ… æ—§æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")


def main():
    print("=" * 60)
    print("ğŸš€ Data-Calculation æµ‹è¯•æ•°æ®åˆ›å»º")
    print("=" * 60)
    
    # æ¸…ç†æ—§æ•°æ®
    cleanup_old_test_data()
    
    # è¿è¡Œæ•°æ®åˆ›å»ºä»»åŠ¡
    tasks = [
        ("åˆ›å»ºç»Ÿè®¡å…ƒæ•°æ®", create_statistical_metadata),
        ("ç”Ÿæˆå­¦ç”Ÿæˆç»©æ•°æ®", lambda: generate_student_scores()[0]),
        ("ç”Ÿæˆé—®å·è°ƒæŸ¥æ•°æ®", lambda: generate_survey_data()[0]),
        ("åˆ›å»ºè®¡ç®—æµ‹è¯•æ•°æ®", create_calculation_test_data)
    ]
    
    results = []
    for task_name, task_func in tasks:
        print(f"\nğŸ“‹ {task_name}")
        print("-" * 40)
        result = task_func()
        results.append((task_name, result))
    
    # æ€»ç»“ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ•°æ®åˆ›å»ºæ€»ç»“")
    print("=" * 60)
    
    all_passed = True
    for task_name, passed in results:
        status = "âœ… å®Œæˆ" if passed else "âŒ å¤±è´¥"
        print(f"   {task_name}: {status}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆï¼")
        print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   - test_student_data.json: å­¦ç”Ÿæˆç»©æ•°æ®")
        print("   - test_survey_data.json: é—®å·è°ƒæŸ¥æ•°æ®")
        print("   - calculation_test_data.json: è®¡ç®—å¼•æ“æµ‹è¯•æ•°æ®")
        print("\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•:")
        print("   python scripts/end_to_end_test.py")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•æ•°æ®åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        sys.exit(1)


if __name__ == "__main__":
    main()