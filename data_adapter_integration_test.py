#!/usr/bin/env python3
"""
æ•°æ®é€‚é…å™¨ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
éªŒè¯æ•°æ®æ¸…æ´—ä¸æ±‡èšå¯¹æ¥çš„å®Œæ•´æµç¨‹
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import asyncio
import json
from datetime import datetime
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.services.calculation_service import CalculationService
from app.database.repositories import DataAdapterRepository

async def test_data_adapter_integration():
    """æ•°æ®é€‚é…å™¨ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
    print("=== æ•°æ®é€‚é…å™¨ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• ===\n")
    
    try:
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        DATABASE_URL = "mysql+pymysql://root:mysql_Lujing2022@117.72.14.166:23506/appraisal_test?charset=utf8mb4"
        engine = create_engine(DATABASE_URL)
        Session = sessionmaker(bind=engine)
        session = Session()
        
        # åˆ›å»ºæ•°æ®é€‚é…å™¨å’Œè®¡ç®—æœåŠ¡
        data_adapter = DataAdapterRepository(session)
        calc_service = CalculationService(session)
        
        print("[OK] æ•°æ®åº“è¿æ¥æˆåŠŸ\n")
        
        # æµ‹è¯•æ‰¹æ¬¡åˆ—è¡¨
        test_batches = ['G7-2025', 'G4-2025', 'G8-2025']
        
        for batch_code in test_batches:
            print(f"[TEST] æµ‹è¯•æ‰¹æ¬¡: {batch_code}")
            print("-" * 50)
            
            # 1. æµ‹è¯•æ•°æ®æºè‡ªåŠ¨é€‰æ‹©
            await test_data_source_selection(data_adapter, batch_code)
            
            # 2. æµ‹è¯•ç§‘ç›®é…ç½®è·å–
            await test_subject_configuration_retrieval(data_adapter, batch_code)
            
            # 3. æµ‹è¯•æ•°æ®å®Œæ•´æ€§éªŒè¯
            await test_data_readiness_check(data_adapter, batch_code)
            
            # 4. æµ‹è¯•è€ƒè¯•æ•°æ®å¤„ç†æµç¨‹
            await test_exam_data_processing(calc_service, batch_code)
            
            # 5. æµ‹è¯•é—®å·æ•°æ®å¤„ç†æµç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
            await test_questionnaire_data_processing(data_adapter, calc_service, batch_code)
            
            # 6. æµ‹è¯•ç»´åº¦ç»Ÿè®¡è®¡ç®—
            await test_dimension_statistics(data_adapter, batch_code)
            
            print(f"âœ… æ‰¹æ¬¡ {batch_code} æµ‹è¯•å®Œæˆ\n")
        
        session.close()
        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def test_data_source_selection(data_adapter: DataAdapterRepository, batch_code: str):
    """æµ‹è¯•æ•°æ®æºè‡ªåŠ¨é€‰æ‹©åŠŸèƒ½"""
    print("  1. æµ‹è¯•æ•°æ®æºè‡ªåŠ¨é€‰æ‹©...")
    
    try:
        # æ£€æŸ¥æ•°æ®å°±ç»ªçŠ¶æ€
        readiness = data_adapter.check_data_readiness(batch_code)
        print(f"     æ•°æ®æºçŠ¶æ€: {readiness['overall_status']}")
        print(f"     æ¸…æ´—æ•°æ®: {'âœ…' if readiness['data_sources']['has_cleaned_data'] else 'âŒ'}")
        print(f"     åŸå§‹æ•°æ®: {'âœ…' if readiness['data_sources']['has_original_data'] else 'âŒ'}")
        
        if readiness['overall_status'] == 'NO_DATA':
            print(f"     âš ï¸ æ‰¹æ¬¡ {batch_code} æ— å¯ç”¨æ•°æ®ï¼Œè·³è¿‡åç»­æµ‹è¯•")
            return False
        
        # è·å–å­¦ç”Ÿåˆ†æ•°æ•°æ®
        scores = data_adapter.get_student_scores(batch_code)
        print(f"     è·å–åˆ° {len(scores)} æ¡å­¦ç”Ÿåˆ†æ•°è®°å½•")
        
        if scores:
            sample = scores[0]
            print(f"     æ•°æ®ç»“æ„ç¤ºä¾‹: {list(sample.keys())[:5]}...")
            
        return len(scores) > 0
        
    except Exception as e:
        print(f"     âŒ æ•°æ®æºé€‰æ‹©æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_subject_configuration_retrieval(data_adapter: DataAdapterRepository, batch_code: str):
    """æµ‹è¯•ç§‘ç›®é…ç½®è·å–"""
    print("  2. æµ‹è¯•ç§‘ç›®é…ç½®è·å–...")
    
    try:
        # è·å–ç§‘ç›®é…ç½®
        subjects = data_adapter.get_subject_configurations(batch_code)
        print(f"     æ‰¾åˆ° {len(subjects)} ä¸ªç§‘ç›®é…ç½®:")
        
        exam_subjects = []
        questionnaire_subjects = []
        
        for subject in subjects:
            subject_type = subject.get('subject_type', '')
            question_type = subject.get('question_type_enum', '')
            
            if question_type == 'questionnaire' or subject_type == 'questionnaire':
                questionnaire_subjects.append(subject)
                print(f"     ğŸ“ é—®å·: {subject['subject_name']} (æ»¡åˆ†: {subject['max_score']})")
            else:
                exam_subjects.append(subject)
                print(f"     ğŸ“š è€ƒè¯•: {subject['subject_name']} (æ»¡åˆ†: {subject['max_score']})")
        
        return {
            'exam_count': len(exam_subjects),
            'questionnaire_count': len(questionnaire_subjects),
            'subjects': subjects
        }
        
    except Exception as e:
        print(f"     âŒ ç§‘ç›®é…ç½®è·å–å¤±è´¥: {e}")
        return None

async def test_data_readiness_check(data_adapter: DataAdapterRepository, batch_code: str):
    """æµ‹è¯•æ•°æ®å®Œæ•´æ€§éªŒè¯"""
    print("  3. æµ‹è¯•æ•°æ®å®Œæ•´æ€§éªŒè¯...")
    
    try:
        readiness = data_adapter.check_data_readiness(batch_code)
        
        print(f"     æ€»ä½“çŠ¶æ€: {readiness['overall_status']}")
        print(f"     å­¦ç”Ÿæ•°é‡: {readiness['student_count']}")
        print(f"     å­¦æ ¡æ•°é‡: {readiness['school_count']}")
        print(f"     ç§‘ç›®æ•°é‡: {readiness['subject_count']}")
        print(f"     æ•°æ®æº: {readiness['data_sources']['primary_source']}")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡æŒ‡æ ‡
        if 'data_quality' in readiness:
            quality = readiness['data_quality']
            print(f"     æ•°æ®å®Œæ•´æ€§: {quality.get('completeness', 'N/A')}")
            print(f"     æ•°æ®ä¸€è‡´æ€§: {quality.get('consistency', 'N/A')}")
        
        return readiness['overall_status'] in ['READY', 'READY_WITH_WARNINGS']
        
    except Exception as e:
        print(f"     âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
        return False

async def test_exam_data_processing(calc_service: CalculationService, batch_code: str):
    """æµ‹è¯•è€ƒè¯•æ•°æ®å¤„ç†æµç¨‹"""
    print("  4. æµ‹è¯•è€ƒè¯•æ•°æ®å¤„ç†æµç¨‹...")
    
    try:
        # è·å–æ‰¹æ¬¡ç§‘ç›®é…ç½®
        subjects = await calc_service._get_batch_subjects(batch_code)
        exam_subjects = [s for s in subjects 
                        if s.get('question_type_enum', '').lower() != 'questionnaire']
        
        if not exam_subjects:
            print("     âš ï¸ æ²¡æœ‰æ‰¾åˆ°è€ƒè¯•ç§‘ç›®")
            return True
        
        print(f"     æ‰¾åˆ° {len(exam_subjects)} ä¸ªè€ƒè¯•ç§‘ç›®")
        
        # æµ‹è¯•å•ç§‘ç›®ç»Ÿè®¡è®¡ç®—
        test_subject = exam_subjects[0]
        subject_name = test_subject['subject_name']
        max_score = test_subject['max_score']
        
        print(f"     æµ‹è¯•ç§‘ç›®: {subject_name} (æ»¡åˆ†: {max_score})")
        
        # è·å–å­¦ç”Ÿåˆ†æ•°æ•°æ®è¿›è¡Œç»Ÿè®¡è®¡ç®—æµ‹è¯•
        scores = calc_service.data_adapter.get_student_scores(batch_code, 'exam')
        subject_scores = [s for s in scores if s['subject_name'] == subject_name]
        
        if subject_scores:
            print(f"     è¯¥ç§‘ç›®æœ‰ {len(subject_scores)} æ¡åˆ†æ•°è®°å½•")
            
            # ç®€å•ç»Ÿè®¡éªŒè¯
            total_scores = [s['score'] for s in subject_scores if s['score'] is not None]
            if total_scores:
                avg_score = sum(total_scores) / len(total_scores)
                print(f"     å¹³å‡åˆ†: {avg_score:.2f}")
                print(f"     å¾—åˆ†ç‡: {(avg_score/max_score)*100:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"     âŒ è€ƒè¯•æ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_questionnaire_data_processing(data_adapter: DataAdapterRepository, calc_service: CalculationService, batch_code: str):
    """æµ‹è¯•é—®å·æ•°æ®å¤„ç†æµç¨‹"""
    print("  5. æµ‹è¯•é—®å·æ•°æ®å¤„ç†æµç¨‹...")
    
    try:
        # è·å–é—®å·ç§‘ç›®
        subjects = data_adapter.get_subject_configurations(batch_code)
        questionnaire_subjects = [s for s in subjects 
                                if s.get('question_type_enum', '').lower() == 'questionnaire']
        
        if not questionnaire_subjects:
            print("     â„¹ï¸ è¯¥æ‰¹æ¬¡æ²¡æœ‰é—®å·ç§‘ç›®")
            return True
        
        print(f"     æ‰¾åˆ° {len(questionnaire_subjects)} ä¸ªé—®å·ç§‘ç›®")
        
        # æµ‹è¯•é—®å·æ˜ç»†æ•°æ®è·å–
        for subject in questionnaire_subjects[:2]:  # æµ‹è¯•å‰2ä¸ªé—®å·
            subject_name = subject['subject_name']
            print(f"     æµ‹è¯•é—®å·: {subject_name}")
            
            # è·å–é—®å·æ˜ç»†æ•°æ®
            questionnaire_details = data_adapter.get_questionnaire_details(batch_code, subject_name)
            print(f"       é—®å·æ˜ç»†è®°å½•: {len(questionnaire_details)}")
            
            if questionnaire_details:
                # æ£€æŸ¥é‡è¡¨ç±»å‹
                scale_types = set(d.get('scale_level') for d in questionnaire_details)
                print(f"       é‡è¡¨ç±»å‹: {scale_types}")
                
                # è·å–é€‰é¡¹åˆ†å¸ƒ
                distribution = data_adapter.get_questionnaire_distribution(batch_code, subject_name)
                print(f"       é€‰é¡¹åˆ†å¸ƒè®°å½•: {len(distribution)}")
        
        return True
        
    except Exception as e:
        print(f"     âŒ é—®å·æ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_dimension_statistics(data_adapter: DataAdapterRepository, batch_code: str):
    """æµ‹è¯•ç»´åº¦ç»Ÿè®¡è®¡ç®—"""
    print("  6. æµ‹è¯•ç»´åº¦ç»Ÿè®¡è®¡ç®—...")
    
    try:
        # è·å–ç»´åº¦é…ç½®
        dimension_config = data_adapter.get_dimension_configurations(batch_code)
        
        if not dimension_config:
            print("     â„¹ï¸ è¯¥æ‰¹æ¬¡æ²¡æœ‰ç»´åº¦é…ç½®")
            return True
        
        print(f"     æ‰¾åˆ° {len(dimension_config)} ä¸ªç»´åº¦é…ç½®")
        
        # æ£€æŸ¥ç»´åº¦æ˜ å°„æ•°æ®
        for config in dimension_config[:3]:  # æµ‹è¯•å‰3ä¸ªç»´åº¦
            dimension_name = config.get('dimension_name', 'Unknown')
            subject_name = config.get('subject_name', 'Unknown')
            
            print(f"     ç»´åº¦: {dimension_name} (ç§‘ç›®: {subject_name})")
            
            # è·å–ç»´åº¦ç»Ÿè®¡æ•°æ®
            dimension_stats = data_adapter.get_dimension_statistics(batch_code, subject_name, dimension_name)
            print(f"       ç»´åº¦ç»Ÿè®¡è®°å½•: {len(dimension_stats)}")
        
        return True
        
    except Exception as e:
        print(f"     âŒ ç»´åº¦ç»Ÿè®¡æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_performance_metrics():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
    print("ğŸ“ˆ æ€§èƒ½æµ‹è¯•...")
    
    try:
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        DATABASE_URL = "mysql+pymysql://root:mysql_Lujing2022@117.72.14.166:23506/appraisal_test?charset=utf8mb4"
        engine = create_engine(DATABASE_URL)
        Session = sessionmaker(bind=engine)
        session = Session()
        
        data_adapter = DataAdapterRepository(session)
        
        # æµ‹è¯•å¤§æ‰¹æ¬¡æ€§èƒ½
        large_batch = 'G7-2025'  # é€šå¸¸æ˜¯æœ€å¤§çš„æ‰¹æ¬¡
        
        start_time = datetime.now()
        
        # æ•°æ®è·å–æ€§èƒ½æµ‹è¯•
        scores = data_adapter.get_student_scores(large_batch)
        data_fetch_time = (datetime.now() - start_time).total_seconds()
        
        print(f"  æ•°æ®è·å–æ€§èƒ½: {len(scores)} æ¡è®°å½•ï¼Œè€—æ—¶ {data_fetch_time:.2f} ç§’")
        print(f"  å¹³å‡å¤„ç†é€Ÿåº¦: {len(scores)/data_fetch_time:.0f} è®°å½•/ç§’")
        
        # æ€§èƒ½åŸºå‡†æ£€æŸ¥
        if data_fetch_time > 10:
            print("  âš ï¸ æ•°æ®è·å–æ€§èƒ½å¯èƒ½éœ€è¦ä¼˜åŒ–")
        else:
            print("  âœ… æ•°æ®è·å–æ€§èƒ½è‰¯å¥½")
        
        session.close()
        return True
        
    except Exception as e:
        print(f"  âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    asyncio.run(test_data_adapter_integration())
    print("\n" + "="*50)
    asyncio.run(test_performance_metrics())