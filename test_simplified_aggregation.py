#!/usr/bin/env python3
"""
ç®€åŒ–æ±‡èšæœåŠ¡æµ‹è¯•è„šæœ¬
æµ‹è¯•é—®å·å¤„ç†å™¨ã€æ±‡èšæœåŠ¡å’Œæ•°æ®ä»“åº“çš„é›†æˆåŠŸèƒ½
"""

import asyncio
import logging
import pandas as pd
from datetime import datetime
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ä½¿ç”¨é¡¹ç›®é…ç½®çš„æ•°æ®åº“è¿æ¥
import os
DATABASE_HOST = os.getenv("DATABASE_HOST", "117.72.14.166")
DATABASE_PORT = os.getenv("DATABASE_PORT", "23506")
DATABASE_USER = os.getenv("DATABASE_USER", "root")
DATABASE_PASSWORD = os.getenv("DATABASE_PASSWORD", "mysql_Lujing2022")
DATABASE_NAME = os.getenv("DATABASE_NAME", "appraisal_test")

DATABASE_URL = (
    f"mysql+pymysql://{DATABASE_USER}:{DATABASE_PASSWORD}"
    f"@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}"
    "?charset=utf8mb4"
)
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(bind=engine)


def test_questionnaire_processor():
    """æµ‹è¯•é—®å·å¤„ç†å™¨"""
    from app.services.questionnaire_processor import (
        QuestionnaireProcessor, QuestionnaireConfig, ScaleType
    )
    
    logger.info("=== æµ‹è¯•é—®å·å¤„ç†å™¨ ===")
    
    processor = QuestionnaireProcessor()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'student_id': ['S001', 'S002', 'S003', 'S001', 'S002', 'S003'],
        'question_id': ['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],
        'raw_score': [4, 3, 5, 2, 1, 3],
        'dimension_code': ['DIM1', 'DIM1', 'DIM1', 'DIM1', 'DIM1', 'DIM1'],
        'dimension_name': ['å­¦ä¹ å…´è¶£', 'å­¦ä¹ å…´è¶£', 'å­¦ä¹ å…´è¶£', 'å­¦ä¹ å…´è¶£', 'å­¦ä¹ å…´è¶£', 'å­¦ä¹ å…´è¶£']
    })
    
    # åˆ›å»ºé…ç½®
    configs = [
        QuestionnaireConfig(
            scale_type=ScaleType.SCALE_5_LIKERT,
            question_id='Q1',
            question_name='æ‚¨å¯¹å­¦ä¹ æ˜¯å¦æ„Ÿå…´è¶£ï¼Ÿ',
            dimension_code='DIM1',
            dimension_name='å­¦ä¹ å…´è¶£'
        ),
        QuestionnaireConfig(
            scale_type=ScaleType.SCALE_5_LIKERT,
            question_id='Q2',
            question_name='æ‚¨è®¤ä¸ºå­¦ä¹ é‡è¦å—ï¼Ÿ',
            dimension_code='DIM1',
            dimension_name='å­¦ä¹ å…´è¶£'
        )
    ]
    
    # å¤„ç†é—®å·æ•°æ®
    result = processor.process_questionnaire_data(test_data, configs, "TEST-BATCH")
    
    logger.info(f"å¤„ç†ç»“æœ: {len(result)} ä¸ªç»´åº¦")
    for dim_stat in result:
        logger.info(f"ç»´åº¦: {dim_stat.dimension_name}, å¹³å‡åˆ†: {dim_stat.avg_score}")
        logger.info(f"  é€‰é¡¹åˆ†å¸ƒ: {len(dim_stat.dimension_option_distributions)} ä¸ªé€‰é¡¹")
        logger.info(f"  é¢˜ç›®æ•°é‡: {len(dim_stat.questions)} ä¸ªé¢˜ç›®")
    
    return True


def test_aggregation_service_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•æ±‡èšæœåŠ¡"""
    from app.services.simplified_aggregation_service import SimplifiedAggregationService
    from app.repositories.simplified_aggregation_repository import SimplifiedAggregationRepository
    from app.database.models import AggregationLevel
    
    logger.info("=== æµ‹è¯•æ±‡èšæœåŠ¡ï¼ˆçœŸå®æ•°æ®ï¼‰===")
    
    db_session = SessionLocal()
    
    try:
        # æŸ¥æ‰¾å¯ç”¨çš„æ‰¹æ¬¡
        query = text("""
            SELECT batch_code, COUNT(DISTINCT student_id) as student_count,
                   COUNT(DISTINCT school_id) as school_count,
                   COUNT(DISTINCT subject_id) as subject_count
            FROM student_score_detail 
            WHERE total_score IS NOT NULL
            GROUP BY batch_code
            HAVING student_count >= 10
            ORDER BY student_count DESC
            LIMIT 3
        """)
        
        result = db_session.execute(query)
        available_batches = result.fetchall()
        
        if not available_batches:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æµ‹è¯•æ‰¹æ¬¡")
            return False
        
        logger.info("å¯ç”¨çš„æµ‹è¯•æ‰¹æ¬¡:")
        for batch in available_batches:
            logger.info(f"  {batch.batch_code}: {batch.student_count}å­¦ç”Ÿ, {batch.school_count}å­¦æ ¡, {batch.subject_count}ç§‘ç›®")
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œæµ‹è¯•
        test_batch = available_batches[0].batch_code
        logger.info(f"ä½¿ç”¨æ‰¹æ¬¡è¿›è¡Œæµ‹è¯•: {test_batch}")
        
        # åˆå§‹åŒ–æœåŠ¡å’Œä»“åº“
        aggregation_service = SimplifiedAggregationService(db_session)
        repository = SimplifiedAggregationRepository(db_session)
        
        def progress_callback(progress, message):
            logger.info(f"è¿›åº¦ {progress}%: {message}")
        
        # æµ‹è¯•åŒºåŸŸçº§æ±‡èš
        logger.info("å¼€å§‹åŒºåŸŸçº§æ±‡èšæµ‹è¯•...")
        regional_result = aggregation_service.aggregate_batch_regional(
            test_batch, progress_callback
        )
        
        if regional_result['success']:
            logger.info(f"åŒºåŸŸçº§æ±‡èšæˆåŠŸ!")
            logger.info(f"  ç§‘ç›®æ•°é‡: {regional_result['subjects_count']}")
            logger.info(f"  å­¦æ ¡æ€»æ•°: {regional_result['total_schools']}")
            logger.info(f"  å­¦ç”Ÿæ€»æ•°: {regional_result['total_students']}")
            logger.info(f"  è€—æ—¶: {regional_result['duration']:.2f}ç§’")
            
            # ä¿å­˜åŒºåŸŸçº§æ•°æ®
            save_result = repository.save_aggregation_data(
                batch_code=test_batch,
                aggregation_level=AggregationLevel.REGIONAL,
                data=regional_result['data'],
                calculation_duration=regional_result['duration']
            )
            logger.info(f"ä¿å­˜åŒºåŸŸçº§æ•°æ®: {save_result}")
        else:
            logger.error(f"åŒºåŸŸçº§æ±‡èšå¤±è´¥: {regional_result['error']}")
            return False
        
        # æµ‹è¯•å­¦æ ¡çº§æ±‡èš
        school_query = text("""
            SELECT DISTINCT school_id 
            FROM student_score_detail 
            WHERE batch_code = :batch_code 
            LIMIT 2
        """)
        school_result = db_session.execute(school_query, {'batch_code': test_batch})
        schools = [row.school_id for row in school_result.fetchall()]
        
        if schools:
            test_school = schools[0]
            logger.info(f"æµ‹è¯•å­¦æ ¡çº§æ±‡èšï¼Œå­¦æ ¡: {test_school}")
            
            school_result = aggregation_service.aggregate_batch_school(
                test_batch, test_school, f"å­¦æ ¡_{test_school}", progress_callback
            )
            
            if school_result['success']:
                logger.info(f"å­¦æ ¡çº§æ±‡èšæˆåŠŸ!")
                logger.info(f"  ç§‘ç›®æ•°é‡: {school_result['subjects_count']}")
                logger.info(f"  å­¦ç”Ÿæ€»æ•°: {school_result['total_students']}")
                logger.info(f"  è€—æ—¶: {school_result['duration']:.2f}ç§’")
                
                # ä¿å­˜å­¦æ ¡çº§æ•°æ®
                save_result = repository.save_aggregation_data(
                    batch_code=test_batch,
                    aggregation_level=AggregationLevel.SCHOOL,
                    data=school_result['data'],
                    school_id=test_school,
                    school_name=f"å­¦æ ¡_{test_school}",
                    calculation_duration=school_result['duration']
                )
                logger.info(f"ä¿å­˜å­¦æ ¡çº§æ•°æ®: {save_result}")
            else:
                logger.error(f"å­¦æ ¡çº§æ±‡èšå¤±è´¥: {school_result['error']}")
        
        # æµ‹è¯•æ•°æ®è¯»å–
        logger.info("æµ‹è¯•æ•°æ®è¯»å–...")
        read_result = repository.get_aggregation_data(
            test_batch, AggregationLevel.REGIONAL
        )
        if read_result:
            logger.info(f"è¯»å–åŒºåŸŸçº§æ•°æ®æˆåŠŸï¼Œè®°å½•ID: {read_result['id']}")
            logger.info(f"  æ•°æ®ç‰ˆæœ¬: {read_result['data_version']}")
            logger.info(f"  å­¦ç”Ÿæ€»æ•°: {read_result['total_students']}")
            logger.info(f"  åˆ›å»ºæ—¶é—´: {read_result['created_at']}")
        
        # æµ‹è¯•æ‰¹æ¬¡çŠ¶æ€
        status_info = repository.get_batch_aggregation_status(test_batch)
        logger.info(f"æ‰¹æ¬¡çŠ¶æ€ä¿¡æ¯: {status_info}")
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•æ±‡èšæœåŠ¡å¤±è´¥: {str(e)}")
        return False
    
    finally:
        db_session.close()


def test_repository_operations():
    """æµ‹è¯•ä»“åº“æ“ä½œ"""
    from app.repositories.simplified_aggregation_repository import SimplifiedAggregationRepository
    from app.database.models import AggregationLevel, CalculationStatus
    from app.schemas.simplified_aggregation_schema import RegionalAggregationData, SubjectStatistics
    
    logger.info("=== æµ‹è¯•ä»“åº“æ“ä½œ ===")
    
    db_session = SessionLocal()
    
    try:
        repository = SimplifiedAggregationRepository(db_session)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            'batch_code': 'TEST-REPO',
            'aggregation_level': 'REGIONAL',
            'total_schools': 5,
            'total_students': 100,
            'subjects': {},
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat(),
            'data_version': '2.0'
        }
        
        # æµ‹è¯•ä¿å­˜
        save_result = repository.save_aggregation_data(
            batch_code='TEST-REPO',
            aggregation_level=AggregationLevel.REGIONAL,
            data=test_data,
            calculation_duration=5.5
        )
        logger.info(f"ä¿å­˜æµ‹è¯•: {save_result}")
        
        # æµ‹è¯•è¯»å–
        read_result = repository.get_aggregation_data(
            'TEST-REPO', AggregationLevel.REGIONAL
        )
        logger.info(f"è¯»å–æµ‹è¯•: æ‰¾åˆ°è®°å½• ID {read_result['id'] if read_result else 'None'}")
        
        # æµ‹è¯•çŠ¶æ€æ›´æ–°
        update_result = repository.update_aggregation_status(
            'TEST-REPO', AggregationLevel.REGIONAL, CalculationStatus.COMPLETED
        )
        logger.info(f"çŠ¶æ€æ›´æ–°æµ‹è¯•: {update_result}")
        
        # æµ‹è¯•æœ€è¿‘è®°å½•æŸ¥è¯¢
        recent_records = repository.get_recent_aggregations(limit=5)
        logger.info(f"æœ€è¿‘è®°å½•æŸ¥è¯¢: æ‰¾åˆ° {len(recent_records)} æ¡è®°å½•")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        delete_result = repository.delete_batch_aggregations('TEST-REPO')
        logger.info(f"æ¸…ç†æµ‹è¯•æ•°æ®: {delete_result}")
        
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•ä»“åº“æ“ä½œå¤±è´¥: {str(e)}")
        return False
    
    finally:
        db_session.close()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹ç®€åŒ–æ±‡èšæœåŠ¡æµ‹è¯•")
    
    test_results = {
        'é—®å·å¤„ç†å™¨': test_questionnaire_processor(),
        'æ±‡èšæœåŠ¡ï¼ˆçœŸå®æ•°æ®ï¼‰': test_aggregation_service_with_real_data(),
        'ä»“åº“æ“ä½œ': test_repository_operations(),
    }
    
    logger.info("=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
    success_count = 0
    for test_name, result in test_results.items():
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
        if result:
            success_count += 1
    
    logger.info(f"æ€»ä½“ç»“æœ: {success_count}/{len(test_results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if success_count == len(test_results):
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç®€åŒ–æ±‡èšæœåŠ¡å·²å°±ç»ª")
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶")


if __name__ == "__main__":
    main()